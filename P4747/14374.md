提供一个**析合树**

处理连续段问题的利器

具体学习可以看[oiwiki](https://oi-wiki.org/ds/divide-combine/)写的非常详细

用到了一个$st$表，一个线段树，一个能找$lca$的玩意和三个单调栈

然后我就写了$class$套$class$套$struct$还指针的吊炸天封装

找$lca$的玩意我用了树剖，同时还要找到一个点到$lca$路径上，从$lca$倒着数的第二个点记作$pre(x,lca)$

对于一个询问$[l,r]$，找到$l$,$r$在析合树上的点$l->x$,$r->y$，然后找到$z=lca(x,y)$，如果z是合点，答案是$[L[pre(x,z)],R[pre(y,z)]]$
```cpp
#include<cstdio>
template<class type>inline const void read(type &in)
{
	in=0;char ch=getchar();bool f=0;
	while (ch<48||ch>57){if (ch=='-')f=1;ch=getchar();}
	while (ch>47&&ch<58)in=(in<<3)+(in<<1)+(ch&15),ch=getchar();
	if (f)in=-in;
}
template<class type>inline const type max(const type &a,const type &b)
{
	return a>b?a:b;
}
template<class type>inline const type min(const type &a,const type &b)
{
	return a<b?a:b;
}
const int N=1e5+10;
int n,m,a[N];
class Divide_Combine_Tree
{
	private:
		template<int maxn,int logn>class ST_Table
		{
			private:
    			int log2[maxn],pow2[logn],mn[maxn][logn],mx[maxn][logn];
    		public:
  				inline const void build(int n,int *a)
				{
    				for (int i=pow2[0]=1;i<logn;i++)pow2[i]=pow2[i-1]<<1;
    				for (int i=2;i<=n;i++)log2[i]=log2[i>>1]+1;
    				for (int i=1;i<=n;i++)mn[i][0]=mx[i][0]=a[i];
    				for (int j=1;j<logn;j++)
      				for (int i=1;i+pow2[j]-1<=n;i++)
	        			mn[i][j]=min(mn[i][j-1],mn[i+pow2[j-1]][j-1]),
    		    		mx[i][j]=max(mx[i][j-1],mx[i+pow2[j-1]][j-1]);
  				}
	  			inline const int querymin(int l,int r)
  				{
  					int k=log2[r-l+1];
  					return min(mn[l][k],mn[r-pow2[k]+1][k]);
  				}
  				inline const int querymax(int l,int r)
  				{
		  			int k=log2[r-l+1];
  					return max(mx[l][k],mx[r-pow2[k]+1][k]);
	  			}
		};
		ST_Table<N,17>st;
		class Segment_Tree
		{
			private:
				struct tree
				{
					int mn,add;
					tree *lson,*rson;
					inline const void plus(int w)
					{
						mn+=w;add+=w;
					}
					inline const void pushup()
					{
						mn=min(lson->mn,rson->mn);
					}
					inline const void pushdown()
					{
						if (add)
							lson->plus(add),
							rson->plus(add),
							add=0;
					}
					inline const void update(int l,int r,int L,int R,int w)
					{
						if (l>R||r<L)return;
						if (l>=L&&r<=R)return plus(w);
						pushdown();
						int mid=l+r>>1;
						lson->update(l,mid,L,R,w);
						rson->update(mid+1,r,L,R,w);
						pushup();
					}
					inline const int query(int l,int r)
					{
						if (l==r)return l;
						pushdown();
						int mid=l+r>>1;
						if (!lson->mn)return lson->query(l,mid);
						else rson->query(mid+1,r);
					}
				}*root,memory_pool[N<<1],*tail;
				inline const void build(tree *&p,int l,int r)
				{
					p=tail++;
					if (l==r)return;
					int mid=l+r>>1;
					build(p->lson,l,mid);
					build(p->rson,mid+1,r);
				}
			public:
				inline const void build()
				{
					tail=memory_pool;build(root,1,n);
				}
				inline const void update(int l,int r,int w)
				{
					root->update(1,n,l,r,w);
				}
				inline const int query()
				{
					return root->query(1,n);
				}
		}sgt;
		template<int maxn>class Heavy_Light_Decomposition
		{
			private:
				int head[maxn],edc,next[maxn],to[maxn],top[maxn],wson[maxn],size[maxn],dep[maxn],fa[maxn],dfn[maxn],dot[maxn];
				inline const void dfs(int p)
				{
					size[p]=1;
					for (int i=head[p];i;i=next[i])
					{
						int son=to[i];
						fa[son]=p;dep[son]=dep[p]+1;
						dfs(son);size[p]+=size[son];
						if (size[son]>size[wson[p]])wson[p]=son;
					}
				}
				inline const void dfs(int p,int tp)
				{
					top[p]=tp;dot[dfn[p]=++*dfn]=p;
					if (wson[p])dfs(wson[p],tp);
					for (int i=head[p];i;i=next[i])
						if (!top[to[i]])
							dfs(to[i],to[i]);
				}
			public:
				inline const void build(int root)
				{
					dfs(root);dfs(root,root);
				}
				inline const void addedge(int u,int v)
				{
					next[++edc]=head[u];to[head[u]=edc]=v;
				}
				inline const int lca(int a,int b)
				{
					while (top[a]^top[b])
						dep[top[a]]>dep[top[b]]
						?a=fa[top[a]]:b=fa[top[b]];
					return dep[a]<dep[b]?a:b;
				}
				inline const int pre(int p,int lca)
				{
					int last=p;
					while (top[p]^top[lca])p=fa[last=top[p]];
					return p==lca?last:dot[dfn[lca]+1];
				}
		};
		Heavy_Light_Decomposition<N<<1>hld;
		inline const bool canmerge(int l,int r)
		{
			return st.querymax(l,r)-st.querymin(l,r)==r-l;
		}
		bool com[N<<1];
		int s1[N],s2[N],s[N],top1,top2,top,id[N],l[N<<1],r[N<<1],m[N<<1];
	public:
		inline const void build()
		{
			st.build(n,a);sgt.build();
    		for (int i=1;i<=n;i++)
			{
    			for (;top1&&a[i]<=a[s1[top1]];top1--)sgt.update(s1[top1-1]+1,s1[top1],a[s1[top1]]);
    			for (;top2&&a[i]>=a[s2[top2]];top2--)sgt.update(s2[top2-1]+1,s2[top2],-a[s2[top2]]);
				sgt.update(s1[top1]+1,i,-a[i]);s1[++top1]=i;
    			sgt.update(s2[top2]+1,i,a[i]);s2[++top2]=i;
    			id[i]=++*id;l[*id]=r[*id]=i;
    			int lm=sgt.query(),now=*id;
    			while (top&&l[s[top]]>=lm)
				{
      				if (com[s[top]]&&canmerge(m[s[top]],i))
					{
						r[s[top]]=i;
						hld.addedge(s[top],now);
						now=s[top--];
						continue;
					}
      				if (canmerge(l[s[top]],i))
      				{
					  	com[++*id]=1;
						l[*id]=l[s[top]];r[*id]=i;m[*id]=l[now];
						hld.addedge(*id,s[top--]);hld.addedge(*id,now);
						now=*id;
						continue;
					}
        			hld.addedge(++*id,now);
        			do hld.addedge(*id,s[top--]);while (top&&!canmerge(l[s[top]],i));
        			l[*id]=l[s[top]];r[*id]=i;
					hld.addedge(*id,s[top--]);
        			now=*id;
    			}
    		s[++top]=now;
    		sgt.update(1,i,-1);
  		}
  		hld.build(s[1]);
  	}
  	inline const void query(int a,int b)
  	{
  		int x=id[a],y=id[b],z=hld.lca(x,y);
  		if (com[z])printf("%d %d\n",l[hld.pre(x,z)],r[hld.pre(y,z)]);
  		else printf("%d %d\n",l[z],r[z]);
  	}
}dct;
int main()
{
	read(n);
	for (int i=1;i<=n;i++)read(a[i]);
	read(m);
	dct.build();
	for (int l,r;m--;)read(l),read(r),dct.query(l,r);
	return 0;
}
```