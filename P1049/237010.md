	此题我没有采用大多数人使用的0-1背包，但算法依旧属于动态规划。
	我的思路历程是从二维dp向一维dp优化，先从二维dp讲起，我所理解的dp是高级的枚举，把所有情况都考虑，然后选出最优的一个，所以我们让dp[i][j]表示决策前i个物品，已装入物品体积为j的状态，记为1，状态转移方程如下：
    if(dp[i-1][j]){
    dp[i][j] = dp[i-1][j];//不放入第i个物品
    dp[i][j+w[i]] = 1;//j+w[i]<=V，体积不溢出
    }
    写这篇题解的时候越发感觉我的方法好像记忆化搜索，我无形中把总体积相同的物品组合看成等效了，统一为dp[i][j]=1这个状态，但以0-1背包思路的视角来看，这其实不过是把价值和相同的组合等效罢了。
    二维dp很好理解，但空间效率太低，所以我们将其优化为一维dp。仔细观察可以发现，二维dp数组每一行在利用完后就完全失去作用，这是优化的基础。我们用dp[j]代表决策前i个物品已经放入的体积，那么状态转移方程如下：
    if(dp[j])
    if(j+w[i]<=V)//体积溢出时，不放入i物品，体积不变
    dp[j+w[i]]=1;
    整体思路就是上面所述了，写的时候最易错的点是j要从大到小遍历，因为一维dp状态转移方程中要保证dp[j]是决策前i-1个物品的状态，而不是决策前i个物品的状态，当j从大到小变的时候，dp[j+w[i]]值的改变永远是基于决策前i-1个物品的状态。而如果j从小到大变的时候，假设j=1,w[1]=1,那么dp[2]的状态被改变，是属于决策前i个物品的状态；当j=2时，dp[j+w[i]]的状态改变基于dp[2]，dp[2]却不是决策前i-1个物品的状态，这样就出现了逻辑错误。
代码如下：
```cpp
#include<iostream>
#include<vector>
#include<algorithm>
using namespace std;
int main() {
	int V, n;
	cin >> V >> n;
	vector<int>w(n);//物品体积
	for (auto i = 0; i < n; ++i) {
		cin >> w[i];
	}
	vector<int>dp(V + 1);
	dp[0] = 1;
	if(w[0]<=V)
	dp[w[0]] = 1;
	for(auto i=1;i<n;++i)
		for (auto j = V-w[i]; j>=0; --j) {
			if (dp[j]) {
				dp[j + w[i]] = 1;
				if (j + w[i] == V) {//如果某一时刻刚好装满，直接输出0，这样可以优化时间
					cout << 0 << endl;
					return 0;
				}
			}
		}
	for (auto j = V; j >= 0; --j) {
		if (dp[j]) {
			cout << V - j << endl;
			break;
		}
	}
	return 0;
}
```
