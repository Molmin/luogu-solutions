
给定一个长度为$n$的序列，你有一次机会选中一段连续的长度不超过$d$的区间，将里面所有数字全部修改为$0$。请找到最长的一段连续区间，使得该区间内所有数字之和不超过$p$。

### 链接

[[POI2015]WIL-Wilcze doły](https://www.luogu.com.cn/problem/P3594) 

### 思路

由于每个数都是正数，那么当然修改的越多越好，干脆直接修改长度为$d$的区间。

枚举选中的连续区间的左右端点和被修改区间的左端点，便可以得到一个$O(n^3)$的算法，TLE。

```cpp
#include<bits/stdc++.h>
#define N 2000010
#define ull unsigned long long 

using namespace std;

int n,d,ans=0;
ull p,a[N],sum[N];

int main() {
	cin>>n>>p>>d;
	for(int i=1;i<=n;i++) {
		cin>>a[i];
		sum[i]=sum[i-1]+a[i];
	}
	
	for(int i=d;i<=n;i++) {
		for(int j=1;j<=i-d+1;j++) {
			for(int k=j;k<=i-d+1;k++) {
				if(sum[i]-sum[j-1]-(sum[k+d-1]-sum[k-1])<=p) ans=max(ans,i-j+1);
			}
		}
	}
	
	cout<<ans<<endl;
	
	return 0;
}
```

这种选连续数和不超过一个数值的题型让我想到了挑程上的尺取法。于是便采用了这种方法进行优化，向一个队列中加数，当和大于了$p$，就开始从被选的数列中枚举修改为$0$的区间的左端点，若不存在修改后小于等于$p$的修改区间，则将队头出队。过程中记录最大区间长度即可。时间复杂度$O(n^2)$，还是TLE。

```cpp
#include<bits/stdc++.h>
#define N 2000010
#define ull unsigned long long 

using namespace std;

int n,d,ans=0,l=1;
ull p,a[N],sum[N],s=0;

int main() {
	cin>>n>>p>>d;
	for(int i=1;i<=n;i++) {
		cin>>a[i];
		sum[i]=sum[i-1]+a[i];
	}
	
	for(int i=1;i<=n;i++) {
		s+=a[i];
		if(i-l+1<=d) {
			ans=max(ans,i-l+1);
			continue;
		}
		if(s>p) {
			bool flag=false;
			for(int j=l;j<=i-d+1;j++) {
				if(s-(sum[j+d-1]-sum[j-1])<=p) {
					flag=true;
					ans=max(ans,i-l+1);
				}
			}
			if(!flag) s-=a[l++];
		}
	}
	
	cout<<ans<<endl;
	
	return 0;
}
```

明显， 被修改的长为$d$的区间内的数和越大越好，于是可以在用尺取法的过程中用单调队列维护单调递增的目前尺取的区间内长为$d$的区间和的区间左端点进行优化即可。

时间复杂度$O(n)$，AC。

### 代码

```cpp
#include<bits/stdc++.h>
#define N 2000010
#define ull unsigned long long 

using namespace std;

int n,d,ans=0,l=1,q[N],head=1,tail=1;
ull p,a[N],sum[N],s=0;

int main() {
	cin>>n>>p>>d;
	for(int i=1;i<=n;i++) {
		cin>>a[i];
		sum[i]=sum[i-1]+a[i];
		if(i<=d) s+=a[i];
	}
	
	q[head]=d;
	for(int i=d+1;i<=n;i++) {
		s+=a[i];
		while(head<=tail&&sum[i]-sum[i-d]>=sum[q[tail]]-sum[q[tail]-d]) tail--;
		q[++tail]=i;
		while(head<=tail&&q[head]-d+1<l) head++;
		while(s-(sum[q[head]]-sum[q[head]-d])>p) {
			s-=a[l++];
			while(head<=tail&&q[head]-d+1<l) head++;
		}
		ans=max(ans,i-l+1);
	}
	
	cout<<ans<<endl;
	
	return 0;
}
```

