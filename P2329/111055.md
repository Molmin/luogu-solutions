## 1 前言
一道不错的剪枝优化(((

就是难度评高了，个人认为PJ~PJ+吧
## 2 思路
### Solution 1:
* 暴力选择放哪些，不放哪些

* 使用没有优化的dfs

部分代码:
```
inline void dfs(int step,int t)
{
	if(step==0)
    {
    	ans=max(ans,t);
    	return ;
	}
	for(int i=n; i>=1; i--) 
	{
		if(A[i]>=b[step]) 
		{
			A[i]-=b[step];
			dfs(step-1,t+1);
			A[i]+=b[step];
		 } 
		dfs(step-1,t);
	} 
	return 0;
}
```
显然，这个算法完全没有一点剪枝，需要遍历每一种情况，显然T飞。

所以我们先考虑直接进行复杂度上的优化~~就是先不考虑卡卡常~~。
### Solution 2:
经过30s的简单思考，我们可以得到一个显而易见的结论:

注意到如果我们构造了一种剪木板的方案，我们将其中一块木板的长度需求减少 $k(k\ge0)$ ，也就是 $a_i=a_i-k$ 之后，这种方案还是可行的。

为什么呢?

拿原来那块木板裁一下就行了。

所以……如果其中 $x$ 块木板能做得到，那么**长度最小**的 $x$ 块也**一定**能做到！换句话说，最优解**之一**一定是选长度最小的 $x$ 块。

这是一个很有用的性质，即证明答案的单调性。

证明单调性之后，排列又可以帮我们减少负担，优化见下。

* 我们可以二分搜索。

* **优化1:二分的dfs只需判断是否能做到即可。**

* **优化2:先排列两个木材长度的序列，二分可以直接进行dfs**

* **优化3:为了减少判断，可以从大往小判断，让每次搜到下一层的数量竟可能少**

部分代码:
```
inline bool dfs(int step)
{
	if(step==1)
	{
		for(int i=1; i<=n; i++) if(A[i]>=b[1]) return 1;
		return 0;
	} 
	for(int i=n; i>=1; i--) if(A[i]>=b[step]) 
	{
		A[i]-=b[step];
		if(A[i]<b[1]) if(dfs(step-1)) return 1;
		A[i]+=b[step];
	} 
	return 0;
}
```

```
	while(l<=r)
	{
		for(int i=1; i<=n; i++) A[i]=a[i];
		mid=(l+r)>>1,now=0;
		for(int i=1; i<=mid; i++) now+=b[i];
		if(dfs(mid)) ans=mid,l=++mid; else r=--mid;
	}
```
那么我们只需要搜 $log_2n$ 次，每次搜不一定搜完，从大往小搜，平均复杂度已经小了很多(因为策略很好，不用搜几次就能到正确答案)，但是还是T的飞起。
### Solution 3:
考虑一个很玄学的数据。

```
2
100 198
3
99 99 100
```
当前尝试的为 $x=3$ ，即全部塞进去。

首先，$100$ 会分给 $198$ ，然后发现 $99$ 放不进去，然后得出不可行。

然后，$100$ 会分给 $100$ ，发现 $99$ 都能塞到 $198$ 里，然后得出可行。

在这个例子里，时间相差不大，但是如果这种 $198$ 和 $99$ 有很多很多呢?

所以，数据卡了一下，很多人又T飞了。

那么，这个数据能告诉我们什么呢?

**在把 $100$ 放入 $198$ 的时候，这个 $198$ 产生了大量无法利用的浪费长度。**

浪费长度……

等等，如果浪费的太多，从而剩下的空间已经不足以放进去另外所有的了(即使剩下的全是 $1$ )，怎么办?

``return 0;``

* **优化4:当剩下最大有效利用空间小于剩下所有需要的空间之和时，必定不可行，跳出。**

上面这句话等价于 $\Sigma_{i=1}^{n}a_i-waste<\Sigma_{i=1}^{step}b_i$ 时 ``return 0;`` ，其中的 $a_i$ 是当前剩下的，就是 dfs 中需要先减掉然后搜完加回来的 $a_i$ 。

那么其实还有一个优化也可以想到(但是用处不大)

* **优化5:起始枚举的右端点保证需要的空间之和小于最大有效的可利用空间。**

上面这句话等价于 $\Sigma_{i=1}^{n}a_i\geq\Sigma_{i=1}^{r}b_i$ 时 ``return 0;``

部分代码:
```
inline bool dfs(int step)
{
	if(step==1)
	{
		for(int i=1; i<=n; i++) if(A[i]>=b[1]) return 1;
		return 0;
	 } 
	if(now>sum) return 0;
	for(int i=n; i>=1; i--) if(A[i]>=b[step]) 
	{
		A[i]-=b[step];
		if(A[i]<b[1]) 
		{
			now+=A[i];
			if(dfs(step-1)) return 1;
			now-=A[i];
		}
		else 
		{
			if(dfs(step-1)) return 1;
		}
		A[i]+=b[step];
	 } 
	return 0;
}
```

```
	sort(b+1,b+m+1);
	for(int i=1; i<=n; i++) if(a[i]<b[1]) a[i]=1145141919810,++k;
	sort(a+1,a+n+1),n-=k;
	for(int i=1; i<=n; i++) sum+=a[i];
	int tmp=0,l=1,r=0,ans=0;
	for(int i=1; i<=m; i++) 
	{
		tmp+=b[i];
		if(tmp>sum) break; else ++r;
	}
}
```
到这里其实你已经 A 了这道题了，但是这道题还有一个小小的优化……
### Solution 4:
我们可以发现，在正在尝试放入的数量 $x$ 很小的时候，几乎可以一次成功，而 $x$ 接近答案的时候总要枚举很多次。

因此我们还可以化二分为倍增，在数据很小的时候进一步优化。

* **优化6:化二分为倍增，进一步减少枚举时的计算量**

这里不给出代码，因为~~懒得写~~上一个方法已经稳过了。
### Code:
```
#include<bits/stdc++.h>
#define int long long
inline int read(){
   int s=0,w=1;
   char ch=getchar();
   while(ch<'0'||ch>'9'){if(ch=='-')w=-1;ch=getchar();}
   while(ch>='0'&&ch<='9') s=s*10+ch-'0',ch=getchar();
   return s*w;
}
int a[53],A[53],n;
int b[1003],m;
int mid,sum,now;
using namespace std;
inline bool dfs(int step)
{
	if(step==1)
	{
		for(int i=1; i<=n; i++) if(A[i]>=b[1]) return 1;
		return 0;
	 } 
	if(now>sum) return 0;
	for(int i=n; i>=1; i--) if(A[i]>=b[step]) 
	{
		A[i]-=b[step];
		if(A[i]<b[1]) 
		{
			now+=A[i];
			if(dfs(step-1)) return 1;
			now-=A[i];
		}
		else 
		{
			if(dfs(step-1)) return 1;
		}
		A[i]+=b[step];
	 } 
	return 0;
}
signed main()
{
	n=read();
	for(int i=1; i<=n; i++) a[i]=read();
	m=read();
	for(int i=1; i<=m; i++) b[i]=read();
	int k=0;
	sort(b+1,b+m+1);
	for(int i=1; i<=n; i++) if(a[i]<b[1]) a[i]=1145141919810,++k;
	sort(a+1,a+n+1),n-=k;
	for(int i=1; i<=n; i++) sum+=a[i];
	int tmp=0,l=1,r=0,ans=0;
	for(int i=1; i<=m; i++) 
	{
		tmp+=b[i];
		if(tmp>sum) break; else ++r;
	}
	while(l<=r)
	{
		for(int i=1; i<=n; i++) A[i]=a[i];
		mid=(l+r)>>1,now=0;
		for(int i=1; i<=mid; i++) now+=b[i];
		if(dfs(mid)) ans=mid,l=++mid; else r=--mid;
	}
	printf("%d",ans);
	return 0;
}
```