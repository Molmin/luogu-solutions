[或许更好的阅读体验。](https://www.cnblogs.com/DRPLANT/articles/3dmq_constant.html)

好阴啊好阴啊好阴啊好阴啊。

关于本题做法，[@xfrvq](https://www.luogu.com.cn/user/368107) 已经讲的很清楚了。这是一篇卡常教程。阅读前建议先阅读 [@xfrvq](https://www.luogu.com.cn/user/368107) 大佬的题解。

# 卡空间常数

以下内容如果您是线性空间写法可以直接忽略，跳过去看卡时间的部分。

本题计算未重构部分的贡献需要存一个大小 $O(m \sqrt m)$ 的数组。然而空间 $O(m \sqrt m)$ 理论不可过。这导致本题空间极其紧张，需要精细实现。

1. 如果把所有 $O(m \sqrt m)$ 个未重构部分的询问对全部一次性存下来的话那必然是寄得不能再寄。但经我测试整个未重构部分占总时间的比例不大，因此可以把未重构部分拆成常数组做，不影响总时间复杂度。然而如果拆的组数过多又会影响时间常数，因此每组中的询问对数尽量越大越好。我的实现是每达到 16000000 个就做一遍并清空。

2. 询问对中不要把所有信息都存下来，只存两个询问的编号就行了。否则空间卡不过去。此外，对于一个询问对 $(i,j)$，如果 $i$ 的 $w$ 值为 0，也无需存储。

3. 重构以及计算已重构部分的贡献时不要用扫描线，至少别用 vector。建议块内排序+双指针。同样是为了卡空间。块内排序实际上不影响总时间复杂度（$O(\sqrt m) \times O(\sqrt m \log{\sqrt m}) = O(m \log{\sqrt m})$）。

4. vector 清空时一定要用新建空 vector 然后 `.swap()` 的方式。`.clear()` 不会释放空间！

# 卡时间常数

本题重中之重。下面会介绍各种我用了以及没用到的卡常方式。

1. `inline`、`register`。基本卡常，没什么好讲的。
2. 较快的快读、快写。如果没有的话可以上网找个。可以把快读快写里面的负数处理删了进一步卡常。
3. 循环展开。完全没用，似乎更慢（？）。
4. 用 `constexpr` 函数把各种可以预处理的东西预处理出来。因为是 `constexpr` 函数所以编译器可以编译期算好。（但是也基本没用。）
5. 阴间调块长。个人感觉调二维分块的块长没啥用。但是调根号重构的块长很有用。我最后调出来根号重构的块长大概在 1200 左右会比较好。
6. 指令集优化。这个效果不错。我跑 1e5 个询问的时间从 10s+ 缩短到了 7s。我估计不加这个很难卡过去。具体如何使用可以去看看 [这篇文章](https://www.luogu.com.cn/blog/ouuan/avx-optimize)。
7. 逐块处理。这是 lxl 教我的卡常方法。大概就是扫 $O(n^{0.25})$ 次，每次只处理一个横着或者竖着的大块。这样就可以把二维分块的数组省掉一位。这么做不是为了卡空间而是为了卡 cache。lxl 称”数组 for 的 cache miss 是致命的“。但是最后我没有写这种卡常方式。因为我代码已经很长了（11.31 KB），懒得再写了。如果实在卡不过去的话可以试试这种方式。

如果仍然卡不过去可以找我要一下代码。但是我也无法保证随时交都能过。~~如果你有充足信心的话也可以直接去找 lxl 开大时限。不过已经开大一次了我估计不会再次开大。~~