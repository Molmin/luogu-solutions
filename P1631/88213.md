# 一道很好的堆优化题

如果暴力把所有$n^2$个和求出来，再排序，最后输出，时间复杂度就为$n^2$个和从小到大排序的时间复杂度：$O(n^2\log{n})$，显然超时。

# 如何优化

首先，把$a$序列和$b$序列从小到大排序，然后建一个小根堆，数据结构类型是一个结构体。这个结构体里应该有3个变量:

```cpp
struct Note
{
	int id_a,id_b,sum;
    //id_a为当前a序列的元素下标
    //id_b为当前b序列的元素下标
    //sum为何两个元素之和
};

```

**为什么这么定义？**

我的思路是这样的：

首先，将$a$序列的所有数与$b$序列的第一个数（即$b$序列最小的数）相加，按照这些和的大小放入一个小根堆中。

接着，输出$n$个最小的值。

首先取出堆顶元素，将堆顶元素中的和输出，然后将这个堆顶元素的$id_b++$,就是将$id_a$对应的值与更大的$b$序列的值相加，再将$sum$更新，再放入堆内，这样循环$n$次就可以了。

# 时间复杂度

要输出$n$个最小的数，堆的$pop$和$push$操作都是$O(\log{n})$,所以总复杂度为$O(n\log{n})$，可过。

$AC$ $Code$

```cpp
#include <iostream>
#include <queue>//STL是个好东西
#include <algorithm>
using namespace std;

struct Note
{
	int id_a,id_b,sum;
	//id_a为当前a序列的元素下表
    //id_b为当前b序列的元素下表
    //sum为何两个元素之和
	bool operator < (const Note& a) const{
		return sum>a.sum;
	}//STL的堆需要重载运算符
};

priority_queue<Note> pq;//小根堆
int n,a[100010],b[100010];

int main(){
	cin>>n;
	for(int i=1;i<=n;i++)
		cin>>a[i];
	for(int i=1;i<=n;i++)
		cin>>b[i];
	sort(a+1,a+1+n);//a序列排序
	sort(b+1,b+1+n);//b序列排序
	for(int i=1;i<=n;i++){
		pq.push((Note){i,1,a[i]+b[1]});
	}//往堆里放值
	for(int i=1;i<=n;i++){
		Note now=pq.top();
		pq.pop();
		cout<<now.sum<<" ";
		now.id_b++;
		now.sum=a[now.id_a]+b[now.id_b];
		pq.push(now);
	}//输出+更新堆
	cout<<endl;//强迫症带换行
	return 0;//完结撒花！
}
```

# 秋豆麻袋！还没讲完！

有人会对这段代码发出疑问：
```cpp
  now.id_b++;
  now.sum=a[now.id_a]+b[now.id_b];
  pq.push(now);
```
如果$id_b>n$了怎么办？$AC$程序里没有加特判啊！

其实不用加。

**Why?**

因为你只取$n$个值，最坏的情况是你对于这个$id_a$的$id_b=n$时，已经取了$n$个值，会自动跳出循坏。

# 真·完结撒花！